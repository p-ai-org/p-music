{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to run nn.py from Juypter in order to use wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file to implement the cnn\n",
    "# @oscars47\n",
    "# first call mastercnn prep to generate np arrays; then run this file\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "\n",
    "# define directories---------\n",
    "MAIN_DIR = '/home/oscar47/Desktop/P-ai'\n",
    "TRAIN_DIR = os.path.join(MAIN_DIR, 'train_data') # to store out .npy files\n",
    "\n",
    "# get np arrays for training!------\n",
    "train_x_ds = np.load(os.path.join(TRAIN_DIR, 'train_x_ds_2.npy')) \n",
    "val_x_ds = np.load(os.path.join(TRAIN_DIR, 'val_x_ds_2.npy')) \n",
    "train_y_ds = np.load(os.path.join(TRAIN_DIR, 'train_y_ds.npy')) \n",
    "val_y_ds = np.load(os.path.join(TRAIN_DIR, 'val_y_ds.npy'))\n",
    "\n",
    "# define shape of incoming and outgoing factors\n",
    "input_shape = train_x_ds[0].shape\n",
    "output_shape = train_y_ds[0].shape\n",
    "print(input_shape, output_shape)\n",
    "\n",
    "print(val_x_ds.shape)\n",
    "print(val_y_ds.shape)\n",
    "\n",
    "# define cnn---------------\n",
    "def build_model(input_shape, size1, size2, size3, dense1, learning_rate):\n",
    "    model = Sequential() # initialize Sequential model object so we can add layers sequentially\n",
    "    #model.add(layers.InputLayer(input_shape)) # add the shape of our input x training vectors\n",
    "    # add a sequence of 5 convolutional layers, alternating Conv2D and MaxPooling\n",
    "    model.add(layers.Conv2D(size1, (3, 3), activation='relu', input_shape = input_shape)) # the (3,3) is size of the kernel -- this is a hyperparam we can use wanb to investigate as well\n",
    "    model.add(layers.MaxPool2D((2,2)))\n",
    "\n",
    "    model.add(layers.Conv2D(size2, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPool2D((2,2)))\n",
    "\n",
    "    model.add(layers.Conv2D(size3, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPool2D((2,2)))\n",
    "\n",
    "    model.add(layers.Flatten()) # convert array to vector\n",
    "    model.add(layers.Dense(dense1, activation='relu')) # add a final dense layer\n",
    "    model.add(layers.Dense(1)) # match output size: which should just be size 1 (a single number)\n",
    "\n",
    "    optimizer = Adam(learning_rate = learning_rate) # compile the model!\n",
    "    model.compile(optimizer=optimizer, loss=keras.losses.CategoricalCrossentropy)\n",
    "\n",
    "    return model\n",
    "\n",
    "# function for training\n",
    "def train(config=None):\n",
    "    with wandb.init(config=config):\n",
    "    # If called by wandb.agent, as below,\n",
    "    # this config will be set by Sweep Controller\n",
    "      config = wandb.config\n",
    "\n",
    "      #pprint.pprint(config)\n",
    "\n",
    "      #initialize the neural net; \n",
    "      global model\n",
    "      model = build_model(input_shape, config.size_1,  config.size_2, config.size_3,  \n",
    "              config.dense1, config.learning_rate)\n",
    "      \n",
    "      #now run training\n",
    "      history = model.fit(\n",
    "        train_x_ds, train_y_ds,\n",
    "        batch_size = config.batch_size,\n",
    "        validation_data=(val_x_ds, val_y_ds),\n",
    "        epochs=config.epochs,\n",
    "        callbacks=[WandbCallback()] #use callbacks to have w&b log stats; will automatically save best model                     \n",
    "      )\n",
    "\n",
    "def train_custom():\n",
    "   global model\n",
    "   model = build_model(input_shape, 32,  32, 32, 32, 0.01)\n",
    "      \n",
    "   #now run training\n",
    "   history = model.fit(\n",
    "      train_x_ds, train_y_ds,\n",
    "      batch_size = 32,\n",
    "      validation_data=(val_x_ds, val_y_ds),\n",
    "      epochs=3,\n",
    "      #callbacks=[WandbCallback()] #use callbacks to have w&b log stats; will automatically save best model                     \n",
    "   )\n",
    "\n",
    "# set dictionary with random search; optimizing val_loss--------------------------\n",
    "sweep_config= {\n",
    "    'method': 'random',\n",
    "    'name': 'val_accuracy',\n",
    "    'goal': 'maximize'\n",
    "}\n",
    "\n",
    "sweep_config['metric']= 'val_accuracy'\n",
    "parameters_dict = {\n",
    "    'epochs': {\n",
    "       'distribution': 'int_uniform',\n",
    "       'min': 15,\n",
    "       'max': 30\n",
    "    },\n",
    "    # for build_dataset\n",
    "     'batch_size': {\n",
    "       'values': [32, 64, 96, 128]\n",
    "    },\n",
    "    'size_1': {\n",
    "       'distribution': 'int_uniform',\n",
    "       'min': 64,\n",
    "       'max': 256\n",
    "    },\n",
    "    'size_2': {\n",
    "       'distribution': 'int_uniform',\n",
    "       'min': 64,\n",
    "       'max': 256\n",
    "    },'size_3': {\n",
    "       'distribution': 'int_uniform',\n",
    "       'min': 64,\n",
    "       'max': 256\n",
    "    },\n",
    "    'dense1': {\n",
    "       'distribution': 'int_uniform',\n",
    "       'min': 64,\n",
    "       'max': 256\n",
    "    },\n",
    "    'learning_rate':{\n",
    "         #uniform distribution between 0 and 1\n",
    "         'distribution': 'uniform', \n",
    "         'min': 0,\n",
    "         'max': 0.1\n",
    "     }\n",
    "}\n",
    "\n",
    "# append parameters to sweep config\n",
    "sweep_config['parameters'] = parameters_dict \n",
    "\n",
    "#train_custom()\n",
    "\n",
    "\n",
    "# login to wandb----------------\n",
    "wandb.init(project=\"Oscar CNN1\", entity=\"p-ai\")\n",
    "\n",
    "# initialize sweep agent\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"Oscar CNN1\", entity=\"p-ai\")\n",
    "wandb.agent(sweep_id, train, count=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aaf8a3611b879056867134183afc22ea709e115b10fb7684e1dbf805b3500c4a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
